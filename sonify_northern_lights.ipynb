{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pretty_midi as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import math\n",
    "import jdc\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sonify:\n",
    "  \n",
    "  def read_data(self, path):\n",
    "    \"\"\"Read the data from the given csv file path.\"\"\"\n",
    "    if not path.endswith(\".csv\"): # If provided path is not a valid csv file\n",
    "      print(\"Invalid file path. Must be .csv file.\")\n",
    "      raise FileNotFoundError()\n",
    "    self.df = pd.read_csv(path) # Loads csv file\n",
    "\n",
    "    # Constants used to add cumulative seconds values in function inside loop\n",
    "    entries_per_day = 12*24 # 12 samples an hour (every 5 mins), 24 hours in a day\n",
    "    seconds_per_day = 60*60*24\n",
    "\n",
    "    # Constants used to create Kp comparison value\n",
    "    self.density_max = np.max(self.df[\"proton_density\"])\n",
    "    self.speed_max = np.max(self.df[\"speed\"])\n",
    "\n",
    "    for i, row in self.df.iterrows(): # Iterates through rows, replacing error data with the average of the previous value and the next valid (i.e., non-error) value\n",
    "      # Data cleanup\n",
    "      self.__cleanup_column(\"proton_density\", row, i, threshold=0)\n",
    "      self.__cleanup_column(\"speed\", row, i, threshold=0)\n",
    "      self.__cleanup_column(\"ion_temp\", row, i, threshold=0)\n",
    "      self.__cleanup_column(\"bz\", row, i, threshold=-10)\n",
    "      self.__cleanup_column(\"phi_angle\", row, i, threshold=0)\n",
    "\n",
    "      # Adding column for seconds since start of dataset\n",
    "      self.__cumulative_seconds(i, entries_per_day, seconds_per_day)\n",
    "\n",
    "      # Adds a column for our own synthetic variable and a column for the difference between that variable and the Kp index.\n",
    "      self.__kp_comparison(i, row) # Not working fully yet\n",
    "\n",
    "    # Just for testing...\n",
    "    plt.plot(self.df[\"cumulative_secs\"], self.df[\"kp_index\"])\n",
    "    plt.title(\"KP Index over time\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(self.df[\"cumulative_secs\"], self.df[\"kp_equiv\"])\n",
    "    plt.title(\"KP Equiv over time\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(self.df[\"cumulative_secs\"], self.df[\"kp_diff\"])\n",
    "    plt.title(\"KP difference over time\")\n",
    "    plt.show()\n",
    "\n",
    "    # print(\"Lowest density value:\", np.min(self.df[\"proton_density\"]))\n",
    "    # print(\"Lowest speed value:\", np.min(self.df[\"speed\"]))\n",
    "\n",
    "    print(self.df)\n",
    "    # read the data into df\n",
    "    # TODO check if path is ok, file format is ok, load data into dataframe\n",
    "  \n",
    "  def __cumulative_seconds(self, i, entries_per_day, seconds_per_day):\n",
    "    \"\"\"Adds a value for the amount of seconds passed since the start of the dataset for the current index.\"\"\"\n",
    "    current_day_in_dataset = math.floor(i / entries_per_day) # Gets the number of seconds to the start of the current day by rounding down\n",
    "    self.df.at[i, \"cumulative_secs\"] = (current_day_in_dataset*seconds_per_day) + self.df.at[i, \"sec_of_day\"] # Adds the start of the current day and the seconds elapsed in current day.\n",
    "\n",
    "  def __kp_comparison(self, i, row):\n",
    "    \"\"\"Generates a synthetic variable based on raw data which is compared to the kp index, the difference can\n",
    "    be a variable we can map to something (maybe a filter parameter?)\"\"\"\n",
    "    density_scaled = self.df.at[i, \"proton_density\"]/self.density_max # The density of the current entry scaled 0-1\n",
    "    speed_scaled = self.df.at[i, \"speed\"]/self.speed_max # The speed of the current entry scaled 0-1\n",
    "    phi_angle = self.df.at[i, \"phi_angle\"]\n",
    "\n",
    "    if i == 0: # Edge case for the first index\n",
    "      local_start_index = 0\n",
    "      local_end_index = 2\n",
    "    elif i == len(self.df.index)-1: # Edge case for the last index\n",
    "      local_start_index = len(self.df.index) - 3\n",
    "      local_end_index = len(self.df.index) - 1\n",
    "    else: # All other indices\n",
    "      local_start_index = i - 1\n",
    "      local_end_index = i + 1\n",
    "\n",
    "    local_phi_values = pd.Series.to_numpy(self.df.loc[local_start_index:local_end_index, \"phi_angle\"])\n",
    "    local_time_values = pd.Series.to_numpy(self.df.loc[local_start_index:local_end_index, \"cumulative_secs\"])\n",
    "\n",
    "    kp_equiv = density_scaled + speed_scaled * 9\n",
    "    self.df.at[i, \"kp_equiv\"] = kp_equiv\n",
    "    self.df.at[i, \"kp_diff\"] = row[\"kp_index\"] - kp_equiv\n",
    "\n",
    "  def __cleanup_column(self, column_title, row, i, threshold=0):\n",
    "    \"\"\"Cleans up the data by finding erroneous data, then setting it to the average of the previous cell and the next non-error cell in the specified column.\"\"\"\n",
    "    if row[column_title] < threshold: # If data is below threshold i.e., is an error\n",
    "      next_valid_value = self.__find_next_non_error_cell(i, column_title, threshold) # Find the next non-error cell in the column\n",
    "      self.df.at[i, column_title] = round((self.df.at[i-1, column_title] + next_valid_value)*0.5, 1) # Sets the current cell to the average of the previous cell and the next non-error one\n",
    "\n",
    "  def __find_next_non_error_cell(self, i, column_title, threshold):\n",
    "    \"\"\"Finds the next value in a column above a given threshold using recursion.\"\"\"\n",
    "    next_value = self.df.at[i+1, column_title]\n",
    "    if next_value > threshold: # If the next cell is above the threshold i.e., not an error, return the next cell\n",
    "      return next_value\n",
    "    else: # If the next cell is also an error, run the function again to try the next cell down\n",
    "      return self.__find_next_non_error_cell(i+1, column_title, threshold)\n",
    "\n",
    "  def read_midi(self, path):\n",
    "\n",
    "    \"\"\"Read the midifile into a dataframe.\"\"\"\n",
    "    \n",
    "    midi_data = pm.PrettyMIDI(path)\n",
    "    if not path.endswith(\".mid\"):\n",
    "      print(\"Invalid file path. Must be .mid file.\")\n",
    "      raise FileNotFoundError()\n",
    "    else: print('Fileload successful.')\n",
    "  \n",
    "    print (f'Estimated tempo of the file: {midi_data.estimate_tempo()}')\n",
    "\n",
    "    segments = (np.array(pm.PrettyMIDI.get_beats(midi_data,start_time=0.0)))\n",
    "    print((segments))\n",
    "    print(segments[-1])\n",
    "    self.midi_grain_start = np.linspace(0, segments[-1], len(segments)*8)\n",
    "    print(len(self.midi_grain_start))\n",
    "\n",
    "\n",
    "  def granulate(self, corpus):\n",
    "    # Idea for how to reference grains:\n",
    "    # Use another dataframe, then we can store Librosa features etc alongside each grain in a table\n",
    "    # We can reference each grain by start and end indices in the numpy array of the audio\n",
    "\n",
    "    self.grains_data = pd.DataFrame()\n",
    "\n",
    "    for song in corpus:\n",
    "      \n",
    "      song_len_samp = song.size # Length of current song in samples\n",
    "      total_grains_in_song = len(self.df.index) # Number of grains in song (just the length of the dataset)\n",
    "      grain_len_samp = math.floor(song_len_samp / total_grains_in_song) # The length of each grain in samples\n",
    "      \n",
    "      for i, row in self.df.iterrows():\n",
    "        self.grains_data[\"song_no\"] = 0 # We'll need a column to tell which song a grain is coming from\n",
    "        self.grain_data[\"grain_in_song\"] = i # The current grain number within the current song\n",
    "        grain_start_index = i * grain_len_samp # The index for the start sample of the current grain\n",
    "        grain_end_index = (i * grain_len_samp) + grain_len_samp # The index for the end sample of the current grain\n",
    "        self.grain_data[\"grain_pos\"] = [grain_start_index, grain_end_index] # Adding grain location to dataframe as list\n",
    "        # Any Librosa features could go here\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this syntax to add methods to Sonify class in other cells\n",
    "\n",
    "%%add_to Sonify\n",
    "def function(self):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fileload successful.\n",
      "Estimated tempo of the file: 228.34817581154812\n",
      "[  0.    0.5   1.    1.5   2.    2.5   3.    3.5   4.    4.5   5.    5.5\n",
      "   6.    6.5   7.    7.5   8.    8.5   9.    9.5  10.   10.5  11.   11.5\n",
      "  12.   12.5  13.   13.5  14.   14.5  15.   15.5  16.   16.5  17.   17.5\n",
      "  18.   18.5  19.   19.5  20.   20.5  21.   21.5  22.   22.5  23.   23.5\n",
      "  24.   24.5  25.   25.5  26.   26.5  27.   27.5  28.   28.5  29.   29.5\n",
      "  30.   30.5  31.   31.5  32.   32.5  33.   33.5  34.   34.5  35.   35.5\n",
      "  36.   36.5  37.   37.5  38.   38.5  39.   39.5  40.   40.5  41.   41.5\n",
      "  42.   42.5  43.   43.5  44.   44.5  45.   45.5  46.   46.5  47.   47.5\n",
      "  48.   48.5  49.   49.5  50.   50.5  51.   51.5  52.   52.5  53.   53.5\n",
      "  54.   54.5  55.   55.5  56.   56.5  57.   57.5  58.   58.5  59.   59.5\n",
      "  60.   60.5  61.   61.5  62.   62.5  63.   63.5  64.   64.5  65.   65.5\n",
      "  66.   66.5  67.   67.5  68.   68.5  69.   69.5  70.   70.5  71.   71.5\n",
      "  72.   72.5  73.   73.5  74.   74.5  75.   75.5  76.   76.5  77.   77.5\n",
      "  78.   78.5  79.   79.5  80.   80.5  81.   81.5  82.   82.5  83.   83.5\n",
      "  84.   84.5  85.   85.5  86.   86.5  87.   87.5  88.   88.5  89.   89.5\n",
      "  90.   90.5  91.   91.5  92.   92.5  93.   93.5  94.   94.5  95.   95.5\n",
      "  96.   96.5  97.   97.5  98.   98.5  99.   99.5 100.  100.5 101.  101.5\n",
      " 102.  102.5 103.  103.5 104.  104.5 105.  105.5 106.  106.5 107.  107.5\n",
      " 108.  108.5 109.  109.5 110.  110.5 111.  111.5 112.  112.5 113.  113.5\n",
      " 114.  114.5 115.  115.5 116.  116.5 117.  117.5 118.  118.5 119.  119.5\n",
      " 120.  120.5 121.  121.5 122.  122.5 123.  123.5 124.  124.5 125.  125.5\n",
      " 126.  126.5 127.  127.5 128.  128.5 129.  129.5 130.  130.5 131.  131.5\n",
      " 132.  132.5 133.  133.5 134.  134.5 135.  135.5 136.  136.5 137.  137.5\n",
      " 138.  138.5 139.  139.5 140.  140.5 141.  141.5 142.  142.5 143.  143.5\n",
      " 144.  144.5 145.  145.5 146.  146.5 147.  147.5 148.  148.5 149.  149.5\n",
      " 150.  150.5 151.  151.5 152.  152.5 153.  153.5 154.  154.5 155.  155.5\n",
      " 156.  156.5]\n",
      "156.5\n",
      "2512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kristian/opt/anaconda3/envs/MCT4001/lib/python3.9/site-packages/pretty_midi/pretty_midi.py:97: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sonify = Sonify()\n",
    "#sonify.read_data(\"/content/drive/MyDrive/Python Assignment 4 Depot/solar_wind_data_2003-10-27 - 2003-11-02_ACTUAL.csv\")\n",
    "sonify.read_midi(\"corpus/02_Dido White Flag_adjusted.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.29221418559854\n",
      "[  0.        0.71428   1.42856   2.14284   2.85712   3.5714    4.28568\n",
      "   4.99996   5.71424   6.42852   7.1428    7.85708   8.57136   9.28564\n",
      "   9.99992  10.7142   11.42848  12.14276  12.85704  13.57132  14.2856\n",
      "  14.99988  15.71416  16.42844  17.14272  17.857    18.57128  19.28556\n",
      "  19.99984  20.71412  21.4284   22.14268  22.85696  23.57124  24.28552\n",
      "  24.9998   25.71408  26.42836  27.14264  27.85692  28.5712   29.28548\n",
      "  29.99976  30.71404  31.42832  32.1426   32.85688  33.57116  34.28544\n",
      "  34.99972  35.714    36.42828  37.14256  37.85684  38.57112  39.2854\n",
      "  39.99968  40.71396  41.42824  42.14252  42.8568   43.57108  44.28536\n",
      "  44.99964  45.71392  46.4282   47.14248  47.85676  48.57104  49.28532\n",
      "  49.9996   50.71388  51.42816  52.14244  52.85672  53.571    54.28528\n",
      "  54.99956  55.71384  56.42812  57.1424   57.85668  58.57096  59.28524\n",
      "  59.99952  60.7138   61.42808  62.14236  62.85664  63.57092  64.2852\n",
      "  64.99948  65.71376  66.42804  67.14232  67.8566   68.57088  69.28516\n",
      "  69.99944  70.71372  71.428    72.14228  72.85656  73.57084  74.28512\n",
      "  74.9994   75.71368  76.42796  77.14224  77.85652  78.5708   79.28508\n",
      "  79.99936  80.71364  81.42792  82.1422   82.85648  83.57076  84.28504\n",
      "  84.99932  85.7136   86.42788  87.14216  87.85644  88.57072  89.285\n",
      "  89.99928  90.71356  91.42784  92.14212  92.8564   93.57068  94.28496\n",
      "  94.99924  95.71352  96.4278   97.14208  97.85636  98.57064  99.28492\n",
      "  99.9992  100.71348 101.42776 102.14204 102.85632 103.5706  104.28488\n",
      " 104.99916 105.71344 106.42772 107.142   107.85628 108.57056 109.28484\n",
      " 109.99912 110.7134  111.42768 112.14196 112.85624 113.57052 114.2848\n",
      " 114.99908 115.71336 116.42764 117.14192 117.8562  118.57048 119.28476\n",
      " 119.99904 120.71332 121.4276  122.14188 122.85616 123.57044 124.28472\n",
      " 124.999   125.71328 126.42756 127.14184 127.85612 128.5704  129.28468\n",
      " 129.99896 130.71324 131.42752 132.1418  132.85608 133.57036 134.28464\n",
      " 134.99892 135.7132  136.42748 137.14176 137.85604 138.57032 139.2846\n",
      " 139.99888 140.71316 141.42744 142.14172 142.856   143.57028 144.28456\n",
      " 144.99884 145.71312 146.4274  147.14168 147.85596 148.57024 149.28452\n",
      " 149.9988  150.71308 151.42736 152.14164 152.85592 153.5702  154.28448\n",
      " 154.99876 155.71304 156.42732 157.1416  157.85588 158.57016 159.28444\n",
      " 159.99872 160.713   161.42728 162.14156 162.85584 163.57012 164.2844\n",
      " 164.99868 165.71296 166.42724 167.14152 167.8558  168.57008 169.28436\n",
      " 169.99864 170.71292 171.4272  172.14148 172.85576 173.57004 174.28432\n",
      " 174.9986  175.71288 176.42716 177.14144 177.85572 178.57    179.28428\n",
      " 179.99856 180.71284 181.42712 182.1414  182.85568 183.56996 184.28424\n",
      " 184.99852 185.7128  186.42708 187.14136 187.85564 188.56992 189.2842\n",
      " 189.99848 190.71276 191.42704 192.14132 192.8556  193.56988 194.28416\n",
      " 194.99844 195.71272 196.427   197.14128 197.85556 198.56984 199.28412\n",
      " 199.9984  200.71268 201.42696 202.14124 202.85552 203.5698  204.28408\n",
      " 204.99836 205.71264 206.42692 207.1412  207.85548 208.56976 209.28404\n",
      " 209.99832 210.7126  211.42688 212.14116 212.85544 213.56972 214.284\n",
      " 214.99828 215.71256 216.42684 217.14112 217.8554  218.56968 219.28396\n",
      " 219.99824 220.71252 221.4268  222.14108 222.85536 223.56964]\n",
      "223.56964000000056\n",
      "2512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('MCT4001')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00e9223df2505016e83dd65347a75f8382f438b2bcd606c5a522cb0e4c79c077"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
