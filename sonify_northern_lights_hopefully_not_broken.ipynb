{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jdc\n",
      "  Downloading jdc-0.0.9-py2.py3-none-any.whl (2.1 kB)\n",
      "Installing collected packages: jdc\n",
      "Successfully installed jdc-0.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install jdc\n",
    "\n",
    "# emin's tonight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pretty_midi as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import math\n",
    "import itertools\n",
    "import jdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sonify:\n",
    "  \n",
    "  def read_data(self, path):\n",
    "    \"\"\"Read the data from the given csv file path.\"\"\"\n",
    "    if not path.endswith(\".csv\"): # If provided path is not a valid csv file\n",
    "      print(\"Invalid file path. Must be .csv file.\")\n",
    "      raise FileNotFoundError()\n",
    "    self.df = pd.read_csv(path) # Loads csv file\n",
    "\n",
    "    # Constants used to add cumulative seconds values in function inside loop\n",
    "    entries_per_day = 12*24 # 12 samples an hour (every 5 mins), 24 hours in a day\n",
    "    seconds_per_day = 60*60*24\n",
    "\n",
    "    # Constants used to create Kp comparison value\n",
    "    self.density_max = np.max(self.df[\"proton_density\"])\n",
    "    self.speed_max = np.max(self.df[\"speed\"])\n",
    "\n",
    "    for i, row in self.df.iterrows(): # Iterates through rows, replacing error data with the average of the previous value and the next valid (i.e., non-error) value\n",
    "      # Data cleanup\n",
    "      self.__cleanup_column(\"proton_density\", row, i, threshold=0)\n",
    "      self.__cleanup_column(\"speed\", row, i, threshold=0)\n",
    "      self.__cleanup_column(\"ion_temp\", row, i, threshold=0)\n",
    "      self.__cleanup_column(\"bz\", row, i, threshold=-10)\n",
    "      self.__cleanup_column(\"phi_angle\", row, i, threshold=0)\n",
    "\n",
    "      # Adding column for seconds since start of dataset\n",
    "      self.__cumulative_seconds(i, entries_per_day, seconds_per_day)\n",
    "\n",
    "      # Adds a column for our own synthetic variable and a column for the difference between that variable and the Kp index.\n",
    "      self.__kp_comparison(i, row) # Not working fully yet\n",
    "\n",
    "    # # Just for testing...\n",
    "    # plt.plot(self.df[\"cumulative_secs\"], self.df[\"kp_index\"])\n",
    "    # plt.title(\"KP Index over time\")\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.plot(self.df[\"cumulative_secs\"], self.df[\"kp_equiv\"])\n",
    "    # plt.title(\"KP Equiv over time\")\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.plot(self.df[\"cumulative_secs\"], self.df[\"kp_diff\"])\n",
    "    # plt.title(\"KP difference over time\")\n",
    "    # plt.show()\n",
    "\n",
    "    # # print(\"Lowest density value:\", np.min(self.df[\"proton_density\"]))\n",
    "    # # print(\"Lowest speed value:\", np.min(self.df[\"speed\"]))\n",
    "\n",
    "    # print(self.df)\n",
    "    # read the data into df\n",
    "    # TODO check if path is ok, file format is ok, load data into dataframe\n",
    "  \n",
    "  def __cumulative_seconds(self, i, entries_per_day, seconds_per_day):\n",
    "    \"\"\"Adds a value for the amount of seconds passed since the start of the dataset for the current index.\"\"\"\n",
    "    current_day_in_dataset = math.floor(i / entries_per_day) # Gets the number of seconds to the start of the current day by rounding down\n",
    "    self.df.at[i, \"cumulative_secs\"] = (current_day_in_dataset*seconds_per_day) + self.df.at[i, \"sec_of_day\"] # Adds the start of the current day and the seconds elapsed in current day.\n",
    "\n",
    "  def __kp_comparison(self, i, row):\n",
    "    \"\"\"Generates a synthetic variable based on raw data which is compared to the kp index, the difference can\n",
    "    be a variable we can map to something (maybe a filter parameter?)\"\"\"\n",
    "    density_scaled = self.df.at[i, \"proton_density\"]/self.density_max # The density of the current entry scaled 0-1\n",
    "    speed_scaled = self.df.at[i, \"speed\"]/self.speed_max # The speed of the current entry scaled 0-1\n",
    "    phi_angle = self.df.at[i, \"phi_angle\"]\n",
    "\n",
    "    if i == 0: # Edge case for the first index\n",
    "      local_start_index = 0\n",
    "      local_end_index = 2\n",
    "    elif i == len(self.df.index)-1: # Edge case for the last index\n",
    "      local_start_index = len(self.df.index) - 3\n",
    "      local_end_index = len(self.df.index) - 1\n",
    "    else: # All other indices\n",
    "      local_start_index = i - 1\n",
    "      local_end_index = i + 1\n",
    "\n",
    "    local_phi_values = pd.Series.to_numpy(self.df.loc[local_start_index:local_end_index, \"phi_angle\"])\n",
    "    local_time_values = pd.Series.to_numpy(self.df.loc[local_start_index:local_end_index, \"cumulative_secs\"])\n",
    "\n",
    "    kp_equiv = density_scaled + speed_scaled * 9\n",
    "    self.df.at[i, \"kp_equiv\"] = kp_equiv\n",
    "    self.df.at[i, \"kp_diff\"] = row[\"kp_index\"] - kp_equiv\n",
    "\n",
    "  def __cleanup_column(self, column_title, row, i, threshold=0):\n",
    "    \"\"\"Cleans up the data by finding erroneous data, then setting it to the average of the previous cell and the next non-error cell in the specified column.\"\"\"\n",
    "    if row[column_title] < threshold: # If data is below threshold i.e., is an error\n",
    "      next_valid_value = self.__find_next_non_error_cell(i, column_title, threshold) # Find the next non-error cell in the column\n",
    "      self.df.at[i, column_title] = round((self.df.at[i-1, column_title] + next_valid_value)*0.5, 1) # Sets the current cell to the average of the previous cell and the next non-error one\n",
    "\n",
    "  def __find_next_non_error_cell(self, i, column_title, threshold):\n",
    "    \"\"\"Finds the next value in a column above a given threshold using recursion.\"\"\"\n",
    "    next_value = self.df.at[i+1, column_title]\n",
    "    if next_value > threshold: # If the next cell is above the threshold i.e., not an error, return the next cell\n",
    "      return next_value\n",
    "    else: # If the next cell is also an error, run the function again to try the next cell down\n",
    "      return self.__find_next_non_error_cell(i+1, column_title, threshold)\n",
    "\n",
    "  def read_midi(self, path):\n",
    "\n",
    "    \"\"\"Read the midifile into a dataframe.\"\"\"\n",
    "    \n",
    "    midi_data = pm.PrettyMIDI(path)\n",
    "    if not path.endswith(\".mid\"):\n",
    "      print(\"Invalid file path. Must be .mid file.\")\n",
    "      raise FileNotFoundError()\n",
    "    else: print('MIDI-Fileload successful.')\n",
    "\n",
    "    segments = (np.array(pm.PrettyMIDI.get_beats(midi_data,start_time=0.0)))\n",
    "    self.midi_grain_start = np.linspace(0, segments[-1], len(segments)*8)\n",
    "\n",
    "    self.midi_grain_len = int(self.midi_grain_start[1] * self.sr)\n",
    "\n",
    "  def read_audio(self, path):\n",
    "    self.sr = 48000\n",
    "    self.song = librosa.load(path, self.sr)[0]\n",
    "\n",
    "  def midi_grains_dataframe(self):\n",
    "    self.midi_grains_data = pd.DataFrame() # Data frame for grains segmented based on previously segmented MIDI file 1/32 notes\n",
    "\n",
    "    for i, row in self.df.iterrows():\n",
    "      self.midi_grains_data.at[i, \"grain_id\"] = i\n",
    "      \n",
    "      grain_start = int(self.midi_grain_start[i] * self.sr) # Find starts sample for MIDI segmented grains\n",
    "      self.midi_grains_data.at[i, \"seg_start\"] = grain_start # Adds start sample to data frame\n",
    "\n",
    "      feature_values = self.extract_features_from_segment(grain_start, self.midi_grain_len)\n",
    "\n",
    "      self.midi_grains_data.at[i, \"spec_band\"] = feature_values[0]\n",
    "      self.midi_grains_data.at[i, \"rms\"] = feature_values[1]\n",
    "      self.midi_grains_data.at[i, \"mfcc\"] = feature_values[2]\n",
    "\n",
    "    # print(self.midi_grains_data)\n",
    "\n",
    "    feature_list = [\"spec_band\", \"rms\", \"mfcc\"]\n",
    "    datapoints_list = [\"proton_density\", \"bz\", \"ion_temp\"]\n",
    "    grains_type = \"midi\"\n",
    "\n",
    "    self.map_features(feature_list, datapoints_list, self.midi_grains_data, grains_type)\n",
    "\n",
    "    print(self.df[[\"midi_spec_band_grain_id\", \"midi_rms_grain_id\", \"midi_mfcc_grain_id\"]])\n",
    "\n",
    "  def dp_grains_dataframe(self):\n",
    "    # Idea for how to reference grains\n",
    "\n",
    "    self.dp_grains_data = pd.DataFrame() # Data frame for grains segmented based on number of data points i.e., 2016 grains\n",
    "\n",
    "    song_len_samp = self.song.size # Length of current song in samples\n",
    "    total_grains_in_song = len(self.df.index) # Number of grains in song (just the length of the dataset)\n",
    "    grain_len = math.floor(song_len_samp / total_grains_in_song) # The length of each grain in samples\n",
    "\n",
    "    for i, row in self.df.iterrows():\n",
    "\n",
    "      self.dp_grains_data.at[i, \"grain_id\"] = i\n",
    "\n",
    "      grain_start = i*grain_len # The start point of the current grain\n",
    "      # print(grain_start)\n",
    "      self.dp_grains_data.at[i, \"grain_start\"] = grain_start # Adding grain start sample index to dataframe\n",
    "      \n",
    "      feature_values = self.extract_features_from_segment(grain_start, grain_len)\n",
    "\n",
    "      self.dp_grains_data.at[i, \"spec_band\"] = feature_values[0]\n",
    "      self.dp_grains_data.at[i, \"rms\"] = feature_values[1]\n",
    "      self.dp_grains_data.at[i, \"mfcc\"] = feature_values[2]\n",
    "\n",
    "    # print(self.dp_grains_data)\n",
    "\n",
    "    feature_list = [\"spec_band\", \"rms\", \"mfcc\"]\n",
    "    datapoints_list = [\"proton_density\", \"bz\", \"ion_temp\"]\n",
    "    grains_type = \"dp\"\n",
    "\n",
    "    self.map_features(feature_list, datapoints_list, self.dp_grains_data, grains_type)\n",
    "\n",
    "    print(self.df[[\"dp_spec_band_grain_id\", \"dp_rms_grain_id\", \"dp_mfcc_grain_id\"]])\n",
    "\n",
    "  def extract_features_from_segment(self, grain_start, grain_len):\n",
    "    \n",
    "    grain_start = int(grain_start)\n",
    "    grain_len = int(grain_len)\n",
    "    \n",
    "    grain = self.song[grain_start:grain_start+grain_len] # Selecting grain data based on start and end points\n",
    "      \n",
    "    # Spectral Bandwidth\n",
    "    spec_band = librosa.feature.spectral_bandwidth(y=grain, sr=self.sr, n_fft=grain_len, hop_length=grain_len, win_length=grain_len)\n",
    "\n",
    "    # Root Mean Square\n",
    "    rms = librosa.feature.rms(y=grain, frame_length=grain_len, hop_length=grain_len)\n",
    "\n",
    "    # Mel Frequency Cepstrum Coefficients\n",
    "    mfcc = librosa.feature.mfcc(y=grain, sr=self.sr, n_mels=1, n_fft=grain_len, hop_length=grain_len, win_length=grain_len)\n",
    "\n",
    "    return [spec_band, rms, mfcc]\n",
    "\n",
    "  def map_features(self, feature_list, datapoints_list, grains_dataframe, grains_type=\"\"):    \n",
    "    for i, feature in enumerate(feature_list):\n",
    "\n",
    "      # MIDI grains data sorted by spectral bandwidth\n",
    "      feature_sorted = grains_dataframe[[\"grain_id\",feature]].sort_values(by=feature, axis='index', kind=\"mergesort\", ignore_index=True)\n",
    "      # Dataset sorted by proton density\n",
    "      self.df.sort_values(by=datapoints_list[i], axis=\"index\", kind=\"mergesort\", ignore_index=True, inplace=True)\n",
    "\n",
    "      grain_id_column_title = grains_type + \"_\" + feature + \"_grain_id\"\n",
    "      print(grain_id_column_title)\n",
    "      feature_sorted.columns = [grain_id_column_title, feature]\n",
    "\n",
    "      # Adds density-corresponding grain ID to dataset for each row\n",
    "      self.df = pd.concat([self.df, feature_sorted[grain_id_column_title]], axis=\"columns\")\n",
    "\n",
    "      # Re-sorts sorted dataset (with new column)\n",
    "      self.df.sort_values(by=\"cumulative_secs\", axis=\"index\", kind=\"mergesort\", ignore_index=True, inplace=True)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack Hardwick\\AppData\\Local\\Temp\\ipykernel_17468\\174358951.py:112: FutureWarning: Pass sr=48000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  self.song = librosa.load(path, self.sr)[0]\n",
      "c:\\Users\\Jack Hardwick\\anaconda3\\lib\\site-packages\\pretty_midi\\pretty_midi.py:97: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI-Fileload successful.\n",
      "midi_spec_band_grain_id\n",
      "midi_rms_grain_id\n",
      "midi_mfcc_grain_id\n",
      "      midi_spec_band_grain_id  midi_rms_grain_id  midi_mfcc_grain_id\n",
      "0                      1481.0             1584.0              1298.0\n",
      "1                       332.0              227.0               301.0\n",
      "2                       270.0              811.0              1258.0\n",
      "3                      1378.0             1456.0              1941.0\n",
      "4                      1518.0             1198.0              1416.0\n",
      "...                       ...                ...                 ...\n",
      "2011                    179.0              198.0              1235.0\n",
      "2012                   1480.0             1891.0               322.0\n",
      "2013                    454.0              734.0               412.0\n",
      "2014                   1409.0             1430.0              1124.0\n",
      "2015                    719.0              856.0               310.0\n",
      "\n",
      "[2016 rows x 3 columns]\n",
      "dp_spec_band_grain_id\n",
      "dp_rms_grain_id\n",
      "dp_mfcc_grain_id\n",
      "      dp_spec_band_grain_id  dp_rms_grain_id  dp_mfcc_grain_id\n",
      "0                     739.0           1278.0             787.0\n",
      "1                     251.0           1169.0            1247.0\n",
      "2                    1003.0            188.0             855.0\n",
      "3                    1645.0             65.0            1212.0\n",
      "4                     494.0           1484.0            1002.0\n",
      "...                     ...              ...               ...\n",
      "2011                 1827.0            893.0            1909.0\n",
      "2012                 1744.0           1150.0             188.0\n",
      "2013                 1274.0           1178.0            1491.0\n",
      "2014                 1945.0            927.0             381.0\n",
      "2015                 1044.0           1691.0             355.0\n",
      "\n",
      "[2016 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "sonify = Sonify()\n",
    "sonify.read_data(\"./solar_wind_data_2003-10-27 - 2003-11-02_ACTUAL.csv\")\n",
    "sonify.read_audio(\"./corpus/02_Dido White Flag.wav\")\n",
    "sonify.read_midi(\"./corpus/02_Dido White Flag_adjusted_2.mid\")\n",
    "sonify.midi_grains_dataframe()\n",
    "sonify.dp_grains_dataframe()\n",
    "#sonify.mapping_midi_grains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "33e85536a753e4289d1e3ca1904fea47091c61e030b0b2f85895695a2354c09d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
